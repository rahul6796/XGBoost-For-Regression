{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Maths Details For Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases , we build the trees using $Similarity$ $Scores$ and then calculate the $Output$ $Values$ for the leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will derive the equations for the $Similarity$ $Score$ and $Output$ $Values$ and show you how the only difference between $Regression$ and $Classification$ is the $Loss$ $Function$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Similarity$ $Score$ and $Output$ $Value$ for $Regression$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Similarity Score = \\frac{Sum Of Residuals, Squared}{NumberOf Residuals + {\\lambda}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and \n",
    "\\begin{equation}\n",
    "Output Value = \\frac{SumOfResiduals}{Number Of Residuals + {\\lambda}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the examples manageable , we will start with this simple $Training$ $Datasets$ for $Regression$.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the data which are taking as an examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for $Regression$ we are using $Drug$ $Dosage$ on the $x-axis$, to predict $Drug$ $Effectiveness$ on the $y-axis$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Both $Regression$ and $Classification$ we already know that $XGBoost$ starts with an initial  prediction that is usually $0.5$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and in both cases we can represent this prediction with a thick black line at $0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the $Residuals$, the differences between the observed and $Predicted$ values ,show us how good the initial prediction is.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in regular , unextreme $Gradient$ $Boost$ , we can quantify how good the prediction is with a $Loss$ $Function$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L(y_{i},p_{i}) = \\frac{1}{2}(y_{i} - p_{i})^{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In $Gradient$ $Boost$ $Regression$ $Details$, we learned how to use this $Loss$ $Function$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review $y_{i}$ stands for the $y-axis$ value from one of the observed values $y_{1}$,$y_{2}$,$y_{3}$.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and $p_{i}$ stands for a prediction , $p_{1}$,$p_{2}$and$p_{3}$ that corresponds to one of the observation $y_{1}$,$y_{2}$and$y_{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example , if are applied this $Loss$ $Function$ to the initial prediction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we add on single term for each observation , so $n$ = $3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{3}L(y_{i},p_{i}) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{3}L(y_{i},p_{i}) = \\frac{1}{2}(y_{1} - p_{1})^{2} +\\frac{1}{2}(y_{2} - p_{2})^{2}+\\frac{1}{2}(y_{3} - p_{3})^{2} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first , second and third trems in the summation corresponds to the first , second and third observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we just plug in number in this formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{3}L(y_{i},p_{i}) = \\frac{1}{2}(-10 - 0.5)^{2} +\\frac{1}{2}(7 - 0.5)^{2}+\\frac{1}{2}(8 - 0.5)^{2} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{3}L(y_{i},p_{i}) = 104.4\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we can apply the $Loss$ $Function$ to new predictions and compare the results to this one to determine if our prediction are improving or not.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot for  again data but as an n example:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Note:-$ if we had $n$ observations, then we add $n$ terms in our $Loss$ $Function$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{3}L(y_{i},p_{i}) = \\frac{1}{2}(y_{1} - p_{1})^{2} +\\frac{1}{2}(y_{2} - p_{2})^{2}+ .....+ \\frac{1}{2}(y_{n}- p_{n})^{2} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have one $Loss$ $Function$ for $Regression$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$XGBoost$  uses those  $Loss$ $Function$ to build trees by minimizing this $Loss$ $Function$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Note-:$ The equation in  the original manuscript  for $XGBoost$ contains an extra trems that i am omitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{n}L(y_{i},p_{i}) + {\\gamma}*T + \\frac{1}{2}{\\lambda}O_{value}^{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trem , ${\\gamma}*T$ , where $T$ is the number of $Terminal$ nodes or, leaves in tree, and {\\gamma}(gamma) is a user definable penalty, is meant to encourage pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I say that it encourage pruning because as we saw in $XGBoost$ can prune even when ${\\gamma}$ = $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am omitting this term because as we saw in $XGBoost$ for $Regression$ and $Clssification$ pruning takes place ofter the full tree in built, and it plays no role in deriving the $Optimal$ $Output$ $Values$ or $Similarity$ $Scores$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so let's talk about this equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{n}L(y_{i},p_{i}) + \\frac{1}{2}{\\lambda}O_{value}^{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is the $Loss$ $Function$ which we just talked about and the second part consist of $Regularization$ term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to find an $Output$ $Value$ $(O_{value})$ for the leaf that minimizes the whole equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in a way that is very similar to $Ridge$ $Regression$ we square to $Output$ $Value$ from the new tree, and scale it with ${\\lambda}$(lambda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on  I will show you that just like $Ridge$ $Regression$ , if ${\\lambda}$ > $0$ then we will shrink the $(O_{value})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Note-:$ Because we optimizing the output value from the first tree, we can replace the prediction $p_{i}$, with the initial prediction $p^{0}$ , plus the $Output$ $Value$ $(O_{value})$ from the new tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\sum_{i=1}^{n}L(y_{i},p^{o}_{i} + O_{value}) + \\frac{1}{2}{\\lambda}O_{value}^{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand all of the terms in this equation.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw the first tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first node as initila prediction and second which we are going to build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use if to build the first tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the three data point for the regression ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by putting  all of the $Residuals$ into a single leaf, and now we need to find an $Output$ $Value$ $(O_{value})$ for this leaf that will minimize this equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
